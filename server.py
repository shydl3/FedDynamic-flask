import flwr as fl
import numpy as np
import matplotlib.pyplot as plt
import torch
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from model import Net

# è®°å½•å…¨å±€æ¨¡å‹æŸå¤±å’Œå‡†ç¡®ç‡
global_loss = []
global_acc = []
weights_over_time = []
client_contributions = {}

# è¯„ä¼°å…¨å±€æ¨¡å‹
def evaluate_global_model(parameters):
    """åœ¨æœ¬åœ° MNIST æµ‹è¯•é›†ä¸Šè¯„ä¼°å…¨å±€æ¨¡å‹"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Net().to(device)

    # åŠ è½½æœåŠ¡å™¨ç«¯èšåˆåçš„æ¨¡å‹å‚æ•°
    params_dict = zip(model.state_dict().keys(), parameters)
    state_dict = {k: torch.tensor(v) for k, v in params_dict}
    model.load_state_dict(state_dict, strict=True)

    # åŠ è½½ MNIST æµ‹è¯•æ•°æ®é›†
    transform = transforms.Compose([transforms.ToTensor()])
    testset = datasets.MNIST(root="./data", train=False, download=True, transform=transform)
    test_loader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)

    model.eval()
    loss_fn = torch.nn.CrossEntropyLoss()
    correct, total, loss = 0, 0, 0.0

    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss += loss_fn(outputs, labels).item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

    acc = correct / total
    avg_loss = loss / len(test_loader)
    
    global_loss.append(avg_loss)
    global_acc.append(acc)
    
    return avg_loss, acc

# è‡ªå®šä¹‰ FedAvg ä»¥è¿›è¡Œå¯è§†åŒ–
class CustomFedAvg(fl.server.strategy.FedAvg):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # åˆå§‹åŒ–è·Ÿè¸ªå®¢æˆ·ç«¯é¦–æ¬¡åŠ å…¥è½®æ¬¡çš„å­—å…¸
        self.client_first_round = {}
        # ä¿æŒåŸæœ‰çš„å®¢æˆ·ç«¯è´¡çŒ®è·Ÿè¸ª
        # ä¿æŒåŸæœ‰çš„æƒé‡å˜åŒ–è·Ÿè¸ª
        self.weights_over_time = []
        self.rnd = 0
        
    def aggregate_fit(self, rnd, results, failures):
        """è”é‚¦è®­ç»ƒè½®æ¬¡èšåˆ"""
        if not results:
            return super().aggregate_fit(rnd, results, failures)

        new_clients = []
        for res in results:
            client_id = res[0].cid
            if client_id not in self.client_first_round:
                self.client_first_round[client_id] = rnd
                new_clients.append(client_id)

        if new_clients:
            print(f"ğŸ”” Round {rnd} - New clients joined: {new_clients}")
            print(f"ğŸ”” Total clients so far: {len(self.client_first_round)}")

        weighted_results = []
        total_weight = 0.0
        for res in results:
            client_id = res[0].cid
            # è®¡ç®—å®¢æˆ·ç«¯å‚ä¸çš„è½®æ¬¡æ•°
            participation_rounds = rnd - self.client_first_round[client_id] + 1
            # ä½¿ç”¨å¯¹æ•°å‡½æ•°ä½¿æƒé‡å¢é•¿æ›´åŠ å¹³æ»‘
            weight = np.log2(participation_rounds + 1)
            total_weight += weight
            
            weighted_results.append((res[0], res[1], weight))
        
        if total_weight > 0:
            weighted_results = [
                (res[0], res[1], res[2] / total_weight) for res in weighted_results
            ]
        
        # ä½¿ç”¨è‡ªå®šä¹‰æƒé‡èšåˆå‚æ•°
        aggregated_parameters = self.aggregate_parameters_weighted(
            [
                (fl.common.parameters_to_ndarrays(res[1].parameters), res[2])
                for res in weighted_results
            ]
        )

        if aggregated_parameters:
            # è¯„ä¼°å…¨å±€æ¨¡å‹
            loss, acc = evaluate_global_model(aggregated_parameters)
            print(f"Round {rnd} - Loss: {loss:.4f}, Accuracy: {acc:.4f}")
            
            # è®°å½•æƒé‡å˜åŒ–
            mean_weight = np.mean(aggregated_parameters[0])
            self.weights_over_time.append(mean_weight)
            
            # è®°å½•å®¢æˆ·ç«¯è´¡çŒ®
            for res in results:
                client_id = res[0].cid
                client_parameters = fl.common.parameters_to_ndarrays(res[1].parameters)
                norm = np.linalg.norm(np.concatenate([p.flatten() for p in client_parameters]))
                if client_id not in client_contributions:
                    client_contributions[client_id] = []
                if len(client_contributions[client_id]) != self.rnd:
                    missing_rounds = rnd - len(client_contributions[client_id]) -1
                    if missing_rounds > 0: 
                        # ä½¿ç”¨0æˆ–å¹³å‡å€¼å¡«å……ç¼ºå¤±çš„è½®æ¬¡
                        fill_value = 0.0  # æˆ–è€…ä½¿ç”¨å¹³å‡å€¼: np.mean(self.client_contributions[client_id])
                        client_contributions[client_id].extend([fill_value] * missing_rounds)
                client_contributions[client_id].append(norm)
                
        self.rnd += 1

        return fl.common.Parameters(
            tensors=fl.common.ndarrays_to_parameters(aggregated_parameters).tensors,
            tensor_type=fl.common.ndarrays_to_parameters(aggregated_parameters).tensor_type
        ), {}

    def aggregate_parameters_weighted(self, parameters_and_weights):
        """æŒ‰æƒé‡èšåˆå‚æ•°"""
        # æå–æƒé‡å’Œå‚æ•°
        parameters = [p[0] for p in parameters_and_weights]
        weights = [p[1] for p in parameters_and_weights]
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        weights = np.array(weights) / np.sum(weights) if np.sum(weights) > 0 else np.array(weights)
        
        # åˆå§‹åŒ–å­˜å‚¨èšåˆå‚æ•°çš„æ•°ç»„
        aggregated_parameters = [
            np.zeros_like(param) for param in parameters[0]
        ]
        
        # æŒ‰æƒé‡èšåˆå‚æ•°
        for param_set, weight in zip(parameters, weights):
            for i, param in enumerate(param_set):
                aggregated_parameters[i] += param * weight
        
        return aggregated_parameters

# å¯åŠ¨æœåŠ¡å™¨
if __name__ == "__main__":
    strategy = CustomFedAvg(
        fraction_fit=1.0,  # 100% å®¢æˆ·ç«¯å‚ä¸
        min_fit_clients=2,  # **è‡³å°‘ 1 ä¸ªå®¢æˆ·ç«¯**
        min_available_clients=2,  # **è‡³å°‘ 3 ä¸ªå®¢æˆ·ç«¯è¿æ¥**
    )

    print("ğŸš€ æœåŠ¡å™¨å¯åŠ¨ï¼Œç­‰å¾… 3 ä¸ªå®¢æˆ·ç«¯è¿æ¥...")
    
    fl.server.start_server(
        server_address="0.0.0.0:8080",  # ç›‘å¬æ‰€æœ‰ IP
        config=fl.server.ServerConfig(num_rounds=5),
        strategy=strategy
    )

    # ========================== #
    # è®­ç»ƒå®Œæˆåå¯è§†åŒ–å¹¶ä¿å­˜å›¾ç‰‡  #
    # ========================== #

    # ğŸ“Œ 1. ç»˜åˆ¶å…¨å±€æ¨¡å‹çš„æŸå¤±æ›²çº¿
    plt.figure(figsize=(6, 4))
    plt.plot(global_loss, label="Loss", color="blue")
    plt.xlabel("Rounds")
    plt.ylabel("Loss")
    plt.title("Global Model Loss over Rounds")
    plt.legend()
    plt.savefig("results/loss.png")
    plt.close()
    
    # ğŸ“Œ 2. ç»˜åˆ¶å…¨å±€æ¨¡å‹çš„å‡†ç¡®ç‡æ›²çº¿
    plt.figure(figsize=(6, 4))
    plt.plot(global_acc, label="Accuracy", color="green")
    plt.xlabel("Rounds")
    plt.ylabel("Accuracy")
    plt.title("Global Model Accuracy over Rounds")
    plt.legend()
    plt.savefig("results/accuracy.png")
    plt.close()

    # ğŸ“Œ 3. ä¿®å¤ weights_over_time è®°å½•åï¼Œç»˜åˆ¶å‚æ•°å˜åŒ–æ›²çº¿
    plt.figure(figsize=(6, 4))
    plt.plot(weights_over_time, label="Mean Weights", color="red")
    plt.xlabel("Rounds")
    plt.ylabel("Mean Weight Value")
    plt.title("Weight Evolution in Federated Learning")
    plt.legend()
    plt.savefig("results/weights.png")
    plt.close()

    # ğŸ“Œ 4. ç»˜åˆ¶ä¸åŒå®¢æˆ·ç«¯çš„è´¡çŒ®æ›²çº¿
    plt.figure(figsize=(6, 4))
    for client_id, updates in client_contributions.items():
        plt.plot(updates, label=f"Client {client_id[:4]}")
    plt.xlabel("Rounds")
    plt.ylabel("Update Norm")
    plt.title("Client Contribution Over Rounds")
    plt.legend()
    plt.savefig("results/client_contribution.png")
    plt.close()

    print("âœ… è®­ç»ƒå®Œæˆï¼Œæ‰€æœ‰å¯è§†åŒ–ç»“æœå·²ä¿å­˜ï¼")
